{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"script","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torchvision.datasets import ImageFolder\nimport torchmetrics\nimport timm\n\n\naffine_par = True\n\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, dilation=1, downsample=None):\n        super(Bottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, stride=stride, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes, affine=affine_par)\n        for i in self.bn1.parameters():\n            i.requires_grad = False\n        padding = dilation\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1,\n                               padding=padding, bias=False, dilation=dilation)\n        self.bn2 = nn.BatchNorm2d(planes, affine=affine_par)\n        for i in self.bn2.parameters():\n            i.requires_grad = False\n        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(planes * 4, affine=affine_par)\n        for i in self.bn3.parameters():\n            i.requires_grad = False\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n        out = self.conv3(out)\n        out = self.bn3(out)\n        if self.downsample is not None:\n            residual = self.downsample(x)\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass ClassifierModule(nn.Module):\n    def __init__(self, inplanes, dilation_series, padding_series, num_classes):\n        super(ClassifierModule, self).__init__()\n        self.conv2d_list = nn.ModuleList()\n        for dilation, padding in zip(dilation_series, padding_series):\n            self.conv2d_list.append(\n                nn.Conv2d(inplanes, num_classes, kernel_size=3, stride=1, padding=padding,\n                          dilation=dilation, bias=True))\n\n        for m in self.conv2d_list:\n            m.weight.data.normal_(0, 0.01)\n\n    def forward(self, x):\n        out = self.conv2d_list[0](x)\n        for i in range(len(self.conv2d_list) - 1):\n            out += self.conv2d_list[i + 1](x)\n        return out\n\n\nclass ResNetMulti(nn.Module):\n    def __init__(self, block, layers, num_classes):\n        self.inplanes = 64\n        super(ResNetMulti, self).__init__()\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n                               bias=False)\n        self.bn1 = nn.BatchNorm2d(64, affine=affine_par)\n        for i in self.bn1.parameters():\n            i.requires_grad = False\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1, ceil_mode=True)  # change\n        self.layer1 = self._make_layer(block, 64, layers[0])\n        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, layers[2], stride=1, dilation=2)\n        self.layer4 = self._make_layer(block, 512, layers[3], stride=1, dilation=4)\n        self.layer6 = ClassifierModule(2048, [6, 12, 18, 24], [6, 12, 18, 24], num_classes)\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                m.weight.data.normal_(0, 0.01)\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n\n    def _make_layer(self, block, planes, blocks, stride=1, dilation=1):\n        downsample = None\n        if (stride != 1\n                or self.inplanes != planes * block.expansion\n                or dilation == 2\n                or dilation == 4):\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inplanes, planes * block.expansion,\n                          kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(planes * block.expansion, affine=affine_par))\n        for i in downsample._modules['1'].parameters():\n            i.requires_grad = False\n        layers = []\n        layers.append(\n            block(self.inplanes, planes, stride, dilation=dilation, downsample=downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes, dilation=dilation))\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        _, _, H, W = x.size()\n\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n        x = self.layer6(x)\n\n        x = torch.nn.functional.interpolate(x, size=(H, W), mode='bilinear')\n\n        if self.training == True:\n            return x, None, None\n\n        return x\n\n    def get_1x_lr_params_no_scale(self):\n        \"\"\"\n        This generator returns all the parameters of the net except for\n        the last classification layer. Note that for each batchnorm layer,\n        requires_grad is set to False in deeplab_resnet.py, therefore this function does not return\n        any batchnorm parameter\n        \"\"\"\n        b = []\n\n        b.append(self.conv1)\n        b.append(self.bn1)\n        b.append(self.layer1)\n        b.append(self.layer2)\n        b.append(self.layer3)\n        b.append(self.layer4)\n\n        for i in range(len(b)):\n            for j in b[i].modules():\n                jj = 0\n                for k in j.parameters():\n                    jj += 1\n                    if k.requires_grad:\n                        yield k\n\n    def get_10x_lr_params(self):\n        \"\"\"\n        This generator returns all the parameters for the last layer of the net,\n        which does the classification of pixel into classes\n        \"\"\"\n        b = []\n        if self.multi_level:\n            b.append(self.layer5.parameters())\n        b.append(self.layer6.parameters())\n\n        for j in range(len(b)):\n            for i in b[j]:\n                yield i\n\n    def optim_parameters(self, lr):\n        return [{'params': self.get_1x_lr_params_no_scale(), 'lr': lr},\n                {'params': self.get_10x_lr_params(), 'lr': 10 * lr}]\n\n\ndef get_deeplab_v2(num_classes=19, pretrain=True, pretrain_model_path='/kaggle/input/pesi_deeplab/other/pesi_deeplab1/1/deeplab_resnet_pretrained_imagenet (1).pth'):\n    model = ResNetMulti(Bottleneck, [3, 4, 23, 3], num_classes)\n\n    # Pretraining loading\n    if pretrain:\n        print('Deeplab pretraining loading...')\n        saved_state_dict = torch.load(pretrain_model_path)\n\n        new_params = model.state_dict().copy()\n        for i in saved_state_dict:\n            i_parts = i.split('.')\n            new_params['.'.join(i_parts[1:])] = saved_state_dict[i]\n        model.load_state_dict(new_params, strict=False)\n\n    return model\n","metadata":{"_uuid":"df479e6a-20ae-41d8-ae6b-38da824504c8","_cell_guid":"04239e48-8322-4167-9369-d43e6aee25bb","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-07-13T08:24:15.041696Z","iopub.execute_input":"2024-07-13T08:24:15.042196Z","iopub.status.idle":"2024-07-13T08:24:15.087734Z","shell.execute_reply.started":"2024-07-13T08:24:15.042158Z","shell.execute_reply":"2024-07-13T08:24:15.086093Z"},"trusted":true},"execution_count":1,"outputs":[{"traceback":["\u001b[0;36m  Cell \u001b[0;32mIn[1], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    class CityScapes(Dataset):\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"],"ename":"SyntaxError","evalue":"incomplete input (3614990204.py, line 1)","output_type":"error"}]}]}